{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RCS Python NLP processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP - Natural Language Processing\n",
    "\n",
    "* Computers good at structured data not words\n",
    "* Humans process language in a way we do not fully understand to apply to computers\n",
    "* noted linguist Chomsky even posits that we have an innate sense of grammar(theory is not confirmed)\n",
    "\n",
    "![Grammars and Languages](img/chomsky_hierarchy.png)\n",
    "More on Chomsky heirarchy - https://en.wikipedia.org/wiki/Chomsky_hierarchy\n",
    "\n",
    "### Where does the human language fit in here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we give structure to our language that computers can understand?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some sentences are impossible to parse without context around them.\n",
    "\n",
    "\"We saw her duck\"\n",
    "* Did we see her lowering her body?\n",
    "* Did we see her favorite animal duck?\n",
    "\n",
    "\"One morning I shot an elephant in my pajamas. How he got in my pajamas, I don't know.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a pipeline\n",
    "\n",
    "* Divide and conquer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Segmentation\n",
    "\n",
    "    * Break the text apart into separate sentences. \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## Word Tokenization \n",
    "      * split apart words whenever there’s a space between them\n",
    "      * process sentences one at a time\n",
    "      *  split words when there's space between them\n",
    "      * punctuation marks - separate tokens, punctuation has meaning (He eats shoots leaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Parts of Speech for Each Token\n",
    " * model is  based on statistics  - computer guesses bases on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Lemmatization\n",
    "* find basic form of the word\n",
    "* one mouse - two mice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID Stop Words\n",
    "* useless filler words without meaning (and a the and so on)\n",
    "* usually hardcoded words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Parsing\n",
    "* find out how each word related to other in the sentence\n",
    "* complex task - state of art in 2017 Google's Parsey McParseface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the right model underneath if we had to do it ourselves...\n",
    "\n",
    "![Algorithm for Data Preparation and Model Building](https://developers.google.com/machine-learning/guides/text-classification/images/TextClassificationFlowchart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Noun Phrases\n",
    "* ID words which go together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)\n",
    "* extracting ideas\n",
    "\n",
    "* People’s names\n",
    "* Company names\n",
    "* Geographic locations (Both physical and political)\n",
    "* Product names\n",
    "* Dates and times\n",
    "* Amounts of money\n",
    "* Names of events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coreference Resolution\n",
    "\n",
    "Yesterday I bought a car. It was expensive.\n",
    "\n",
    "* Coreference resolution - difficult step in our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install through conda not pip on Windows!\n",
    "conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warnings can be ignored here, comes from compiling against older numpy than our version\n",
    "### https://stackoverflow.com/questions/40845304/runtimewarning-numpy-dtype-size-changed-may-indicate-binary-incompatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import alraedy processed learning data for English\n",
    "python -m spacy download en_core_web_lg\n",
    "\n",
    "## About 900MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load our NLP model\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = '''Riga (/ˈriːɡə/; Latvian: Rīga [ˈriːɡa] (About this sound listen)) is the capital and largest city of Latvia. With 641,481 inhabitants (2016),[4] it is also the largest city in the three Baltic states, home to one third of Latvia's population and one tenth of the three Baltic states' combined population.[8] The city lies on the Gulf of Riga, at the mouth of the Daugava. Riga's territory covers 307.17 square kilometres (118.60 square miles) and lies between one and ten metres (3 feet 3 inches and 32 feet 10 inches) above sea level,[9] on a flat and sandy plain.[9]\n",
    "\n",
    "Riga was founded in 1201 and is a former Hanseatic League member. Riga's historical centre is a UNESCO World Heritage Site, noted for its Art Nouveau/Jugendstil architecture and 19th century wooden architecture.[10] Riga was the European Capital of Culture during 2014, along with Umeå in Sweden. Riga hosted the 2006 NATO Summit, the Eurovision Song Contest 2003, the 2006 IIHF Men's World Ice Hockey Championships and the 2013 World Women's Curling Championship. It is home to the European Union's office of European Regulators for Electronic Communications (BEREC).\n",
    "\n",
    "In 2016, Riga received over 1.4 million visitors.[11] It is served by Riga International Airport, the largest and busiest airport in the Baltic states. Riga is a member of Eurocities,[12] the Union of the Baltic Cities (UBC)[13] and Union of Capitals of the European Union (UCEU).[14]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need to clean our data first a bit\n",
    "# regular expressions to the rescue!\n",
    "import re\n",
    "# how to construct regex queries https://docs.python.org/3/howto/regex.html#regex-howto\n",
    "\n",
    "# where do regular expressions belong on Chomsky hierarchy: https://cstheory.stackexchange.com/questions/1047/where-do-most-regex-implementations-fall-on-the-complexity-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to escape []!!! \n",
    "# these need escaping  . ^ $ * + ? { } [ ] \\ | ( )\n",
    "cleanriga = re.sub('\\[.*?\\]', '', mydata) # we replace sq brackets and contents inside with ''\n",
    "cleanriga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the text with spaCy. This runs the entire pipeline we discussed earlier\n",
    "parsedriga = nlp(cleanriga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  gathering a list of named entities and entity types detected in our document\n",
    "for entity in parsedriga.ents:\n",
    "    print(f\"{entity.text} ({entity.label_})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entity types https://spacy.io/usage/linguistic-features#entity-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go deeper and find out statements about our text\n",
    "import textacy.extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract semi-structured statements\n",
    "statements = textacy.extract.semistructured_statements(parsedriga, \"Riga\")\n",
    "type(statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Here are the things I know about Riga:\")\n",
    "\n",
    "for statement in statements:\n",
    "    subject, verb, fact = statement\n",
    "    print(f\" {subject} - {verb} {fact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we do better?\n",
    "# We need more data for our nlp to process.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/riga.txt', 'r', encoding=\"utf8\") as f:\n",
    "    myriga = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanriga = re.sub('\\[.*?\\]', '', myriga) \n",
    "cleanriga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsedrigaful = nlp(cleanriga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in parsedrigaful.ents:\n",
    "    print(f\"{entity.text} ({entity.label_})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = textacy.extract.semistructured_statements(parsedrigaful, \"Riga\")\n",
    "type(statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Here are the things I know about Riga:\")\n",
    "\n",
    "for statement in statements:\n",
    "    subject, verb, fact = statement\n",
    "    print(f\" {subject} - {verb} {fact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract noun chunks that appear at least 3 times\n",
    "noun_chunks = textacy.extract.noun_chunks(parsedrigaful, min_freq=3)\n",
    "\n",
    "# Convert noun chunks to lowercase strings\n",
    "noun_chunks = map(str, noun_chunks)\n",
    "noun_chunks = map(str.lower, noun_chunks)\n",
    "\n",
    "# Print out any nouns that are at least 2 words long\n",
    "for noun_chunk in set(noun_chunks):\n",
    "    if len(noun_chunk.split(\" \")) > 1:\n",
    "        print(noun_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO Install the neuralcoref library and add Coreference Resolution to your pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "   * https://medium.com/@ageitgey/natural-language-processing-is-fun-9a0bff37854e\n",
    "    \n",
    "   *  https://developers.google.com/machine-learning/guides/text-classification/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
